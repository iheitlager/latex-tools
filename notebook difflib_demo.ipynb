{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding difflib.SequenceMatcher\n",
    "\n",
    "This notebook demonstrates how `difflib.SequenceMatcher` works using the abstracts from old_file.tex and new_file.tex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the abstracts from both files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old abstract length: 2268 characters\n",
      "New abstract length: 2285 characters\n"
     ]
    }
   ],
   "source": [
    "old_abstract = r\"\"\"\\def\\mytitle{Navigating Digital Innovation in Asset-Intensive Industries: A Process Model Informed by Design Science}\n",
    "\\def\\myabstract{Companies in asset-intensive industries, such as aviation and railways, face unique digital transformation challenges due to the misalignment between the rapid evolution of digital technologies and decades-long asset lifecycles. Existing innovation frameworks are inadequate for managing this complexity, which in turn creates tensions between innovation requirements and operational reliability demands. This paper therefore investigates how asset-intensive companies can systematically integrate digital innovations, while fully complying with regulatory constraints and safety requirements. We employ a design science approach in a study of Nederlandse Spoorwegen (NS), the Dutch national railway operator, focusing specifically on the implementation of AI-driven CCTV systems within the operations of NS. Drawing on a literature review and participant-observer as well as interview data, we develop six design propositions that address the key digital innovation challenges of asset-intensive companies in the area of market readiness assessment, modular architecture, regulatory compliance, temporal coordination, ecosystem governance, and organizational capability development. Using these design propositions, we develop the Iterative Development \\& Adoption Model (IDAM) that operationalizes market maturity assessment through market readiness levels to guide make-or-buy transitions across four iterative phases: ideate, assess, realise, and review. This model includes a Development Reference Architecture for emerging technologies and an Integration Reference Architecture for more mature technologies, enabling concurrent sourcing strategies based on technological maturity. IDAM provides actionable guidance for decisions about technology adoption in asset-intensive contexts, thereby offering a systematic approach to innovation management in industries with very long asset lifecycles and huge regulatory constraints.}\n",
    "\\def\\mykeywords{design science; engineering design; technology adoption; digital transformation; product development; asset lifecycle; modular architecture; market readiness; operational reliability}\n",
    "\"\"\"\n",
    "\n",
    "new_abstract = r\"\"\"\\def\\mytitle{Navigating Digital Transformation in Asset-Intensive Companies: A Process Model Informed by Design Science}\n",
    "\\def\\myabstract{Companies in \\textbf{asset-intensive industries}, such as aviation and railways, face unique digital transformation challenges due to the misalignment between the rapid evolution of digital technologies and decades-long asset lifecycles. Existing innovation frameworks are inadequate for managing this complexity, which in turn creates tensions between innovation requirements and operational reliability demands. This paper therefore investigates how asset-intensive companies can systematically integrate digital technologies, while fully complying with regulatory constraints and safety requirements. We employ a design science approach in a study of Nederlandse Spoorwegen (NS), the Dutch national railway operator, focusing specifically on the implementation of AI-driven CCTV systems within the operations of NS. Drawing on a literature review and participant-observer as well as interview data, we develop six design propositions that address the key digital transformation challenges of asset-intensive companies in the area of market readiness assessment, modular architecture, regulatory compliance, temporal coordination, ecosystem governance, and organizational capability development. Using these design propositions, we develop the Iterative Development \\& Adoption Model (IDAM) that operationalizes market maturity assessment through market readiness levels to guide make-or-buy transitions across four iterative phases: ideate, assess, realise, and review. This model includes a Development Reference Architecture for emerging technologies and an Integration Reference Architecture for more mature technologies, enabling concurrent sourcing strategies based on technological maturity. IDAM provides actionable guidance for decisions about technology adoption in asset-intensive contexts, thereby offering a systematic approach to innovation management in industries with very long asset lifecycles and huge regulatory constraints.}\n",
    "\\def\\mykeywords{design science; engineering design; technology adoption; digital transformation; product development; asset lifecycle; modular architecture; market readiness; operational reliability}\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Old abstract length: {len(old_abstract)} characters\")\n",
    "print(f\"New abstract length: {len(new_abstract)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a SequenceMatcher object\n",
    "\n",
    "`SequenceMatcher` compares two sequences (strings, lists, etc.) and finds matching blocks.\n",
    "\n",
    "**Key parameters:**\n",
    "- `isjunk`: A function to filter out 'junk' elements (we use `None` to keep everything)\n",
    "- `a`: The first sequence (old text)\n",
    "- `b`: The second sequence (new text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceMatcher created successfully!\n",
      "Type: <class 'difflib.SequenceMatcher'>\n"
     ]
    }
   ],
   "source": [
    "# Create a SequenceMatcher to compare the two abstracts\n",
    "matcher = difflib.SequenceMatcher(None, old_abstract, new_abstract)\n",
    "\n",
    "print(\"SequenceMatcher created successfully!\")\n",
    "print(f\"Type: {type(matcher)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get the similarity ratio\n",
    "\n",
    "The `ratio()` method returns a measure of similarity as a float in [0, 1].\n",
    "- 1.0 means the sequences are identical\n",
    "- 0.0 means they have nothing in common\n",
    "\n",
    "**Formula:** `2.0 * M / T`\n",
    "- M = number of matching characters\n",
    "- T = total number of characters in both sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity ratio: 0.9844\n",
      "Similarity percentage: 98.44%\n"
     ]
    }
   ],
   "source": [
    "ratio = matcher.ratio()\n",
    "print(f\"Similarity ratio: {ratio:.4f}\")\n",
    "print(f\"Similarity percentage: {ratio * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get matching blocks\n",
    "\n",
    "`get_matching_blocks()` returns a list of triples `(i, j, n)` where:\n",
    "- `i`: start index in sequence a (old text)\n",
    "- `j`: start index in sequence b (new text)  \n",
    "- `n`: length of the matching block\n",
    "\n",
    "This means: `a[i:i+n] == b[j:j+n]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matching blocks: 8\n",
      "\n",
      "First 10 matching blocks:\n",
      "Block 0: pos_old=0, pos_new=0, length=32\n",
      "  Text: '\\def\\mytitle{Navigating Digital '\n",
      "\n",
      "Block 1: pos_old=37, pos_new=41, length=25\n",
      "  Text: 'ation in Asset-Intensive '\n",
      "\n",
      "Block 2: pos_old=69, pos_new=72, length=78\n",
      "  Text: 'ies: A Process Model Informed by Design Science}\n",
      "\\...'\n",
      "\n",
      "Block 3: pos_old=147, pos_new=158, length=26\n",
      "  Text: 'asset-intensive industries'\n",
      "\n",
      "Block 4: pos_old=173, pos_new=185, length=467\n",
      "  Text: ', such as aviation and railways, face unique digit...'\n",
      "\n",
      "Block 5: pos_old=650, pos_new=663, length=440\n",
      "  Text: 's, while fully complying with regulatory constrain...'\n",
      "\n",
      "Block 6: pos_old=1095, pos_new=1112, length=1173\n",
      "  Text: 'ation challenges of asset-intensive companies in t...'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matching_blocks = matcher.get_matching_blocks()\n",
    "\n",
    "print(f\"Number of matching blocks: {len(matching_blocks)}\\n\")\n",
    "print(\"First 10 matching blocks:\")\n",
    "for i, (a_idx, b_idx, size) in enumerate(matching_blocks[:10]):\n",
    "    if size > 0:  # Skip the final dummy block\n",
    "        matching_text = old_abstract[a_idx:a_idx+size]\n",
    "        print(f\"Block {i}: pos_old={a_idx}, pos_new={b_idx}, length={size}\")\n",
    "        print(f\"  Text: '{matching_text[:50]}...'\" if len(matching_text) > 50 else f\"  Text: '{matching_text}'\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Get opcodes (operations)\n",
    "\n",
    "`get_opcodes()` returns a list of 5-tuples describing how to turn sequence a into sequence b.\n",
    "\n",
    "Each tuple is: `(tag, i1, i2, j1, j2)` where:\n",
    "- `tag`: operation type ('equal', 'replace', 'delete', 'insert')\n",
    "- `i1:i2`: slice of sequence a\n",
    "- `j1:j2`: slice of sequence b\n",
    "\n",
    "**Operations:**\n",
    "- `'equal'`: `a[i1:i2] == b[j1:j2]` (no change)\n",
    "- `'replace'`: `a[i1:i2]` should be replaced by `b[j1:j2]`\n",
    "- `'delete'`: `a[i1:i2]` should be deleted (j1 == j2)\n",
    "- `'insert'`: `b[j1:j2]` should be inserted at a[i1:i1] (i1 == i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of operations: 13\n",
      "\n",
      "All operations:\n",
      "equal    a[   0:  32] == b[   0:  32] (length: 32)\n",
      "         '\\def\\mytitle{Navigating Digital '\n",
      "\n",
      "replace  a[  32:  37] -> b[  32:  41]\n",
      "         OLD: 'Innov'\n",
      "         NEW: 'Transform'\n",
      "\n",
      "equal    a[  37:  62] == b[  41:  66] (length: 25)\n",
      "         'ation in Asset-Intensive '\n",
      "\n",
      "replace  a[  62:  69] -> b[  66:  72]\n",
      "         OLD: 'Industr'\n",
      "         NEW: 'Compan'\n",
      "\n",
      "equal    a[  69: 147] == b[  72: 150] (length: 78)\n",
      "         'ies: A Process Model Informed by Design Science}\n",
      "\\def\\myabstract{Companies in '\n",
      "\n",
      "insert   b[ 150: 158]\n",
      "         INS: '\\textbf{'\n",
      "\n",
      "equal    a[ 147: 173] == b[ 158: 184] (length: 26)\n",
      "         'asset-intensive industries'\n",
      "\n",
      "insert   b[ 184: 185]\n",
      "         INS: '}'\n",
      "\n",
      "equal    a[ 173: 640] == b[ 185: 652] (length: 467)\n",
      "\n",
      "replace  a[ 640: 650] -> b[ 652: 663]\n",
      "         OLD: 'innovation'\n",
      "         NEW: 'technologie'\n",
      "\n",
      "equal    a[ 650:1090] == b[ 663:1103] (length: 440)\n",
      "\n",
      "replace  a[1090:1095] -> b[1103:1112]\n",
      "         OLD: 'innov'\n",
      "         NEW: 'transform'\n",
      "\n",
      "equal    a[1095:2268] == b[1112:2285] (length: 1173)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opcodes = matcher.get_opcodes()\n",
    "\n",
    "print(f\"Number of operations: {len(opcodes)}\\n\")\n",
    "print(\"All operations:\")\n",
    "for tag, i1, i2, j1, j2 in opcodes:\n",
    "    old_text = old_abstract[i1:i2]\n",
    "    new_text = new_abstract[j1:j2]\n",
    "    \n",
    "    if tag == 'equal':\n",
    "        print(f\"{tag:8s} a[{i1:4d}:{i2:4d}] == b[{j1:4d}:{j2:4d}] (length: {i2-i1})\")\n",
    "        if i2 - i1 < 100:\n",
    "            print(f\"         '{old_text}'\")\n",
    "    elif tag == 'replace':\n",
    "        print(f\"{tag:8s} a[{i1:4d}:{i2:4d}] -> b[{j1:4d}:{j2:4d}]\")\n",
    "        print(f\"         OLD: '{old_text}'\")\n",
    "        print(f\"         NEW: '{new_text}'\")\n",
    "    elif tag == 'delete':\n",
    "        print(f\"{tag:8s} a[{i1:4d}:{i2:4d}]\")\n",
    "        print(f\"         DEL: '{old_text}'\")\n",
    "    elif tag == 'insert':\n",
    "        print(f\"{tag:8s} b[{j1:4d}:{j2:4d}]\")\n",
    "        print(f\"         INS: '{new_text}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All operations with LaTeX markup:\n",
      "================================================================================\n",
      "\\def\\mytitle{Navigating Digital \\old{Innov}\\new{Transform}ation in Asset-Intensive \\old{Industr}\\new{Compan}ies: A Process Model Informed by Design Science}\n",
      "\\def\\myabstract{Companies in \\new{\\textbf{}asset-intensive industries\\new{}}, such as aviation and railways, face unique digital transformation challenges due to the misalignment between the rapid evolution of digital technologies and decades-long asset lifecycles. Existing innovation frameworks are inadequate for managing this complexity, which in turn creates tensions between innovation requirements and operational reliability demands. This paper therefore investigates how asset-intensive companies can systematically integrate digital \\old{innovation}\\new{technologie}s, while fully complying with regulatory constraints and safety requirements. We employ a design science approach in a study of Nederlandse Spoorwegen (NS), the Dutch national railway operator, focusing specifically on the implementation of AI-driven CCTV systems within the operations of NS. Drawing on a literature review and participant-observer as well as interview data, we develop six design propositions that address the key digital \\old{innov}\\new{transform}ation challenges of asset-intensive companies in the area of market readiness assessment, modular architecture, regulatory compliance, temporal coordination, ecosystem governance, and organizational capability development. Using these design propositions, we develop the Iterative Development \\& Adoption Model (IDAM) that operationalizes market maturity assessment through market readiness levels to guide make-or-buy transitions across four iterative phases: ideate, assess, realise, and review. This model includes a Development Reference Architecture for emerging technologies and an Integration Reference Architecture for more mature technologies, enabling concurrent sourcing strategies based on technological maturity. IDAM provides actionable guidance for decisions about technology adoption in asset-intensive contexts, thereby offering a systematic approach to innovation management in industries with very long asset lifecycles and huge regulatory constraints.}\n",
      "\\def\\mykeywords{design science; engineering design; technology adoption; digital transformation; product development; asset lifecycle; modular architecture; market readiness; operational reliability}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"All operations with LaTeX markup:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for tag, i1, i2, j1, j2 in opcodes:\n",
    "    old_text = old_abstract[i1:i2]\n",
    "    new_text = new_abstract[j1:j2]\n",
    "    \n",
    "    if tag == 'equal':\n",
    "        print(old_text, end='')\n",
    "    elif tag == 'replace':\n",
    "        print(f\"\\\\old{{{old_text}}}\\\\new{{{new_text}}}\", end='')\n",
    "    elif tag == 'delete':\n",
    "        print(f\"\\\\old{{{old_text}}}\", end='')\n",
    "    elif tag == 'insert':\n",
    "        print(f\"\\\\new{{{new_text}}}\", end='')\n",
    "\n",
    "print()  # Final newline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing tokenizer:\n",
      "================================================================================\n",
      "\n",
      "Input:  in \\textbf{asset-intensive industries}, such\n",
      "Tokens: ['in', ' ', '\\\\textbf', '{', 'asset', '-', 'intensive', ' ', 'industries', '}', ',', ' ', 'such']\n",
      "Rejoined: in \\textbf{asset-intensive industries}, such\n",
      "Match: True\n",
      "\n",
      "Input:  \\def\\mytitle{Some Title}\n",
      "\n",
      "Tokens: ['\\\\def', '\\\\mytitle', '{', 'Some', ' ', 'Title', '}', '\\n']\n",
      "Rejoined: \\def\\mytitle{Some Title}\n",
      "\n",
      "Match: True\n",
      "\n",
      "Input:  text with \\& special chars\n",
      "Tokens: ['text', ' ', 'with', ' ', '\\\\&', ' ', 'special', ' ', 'chars']\n",
      "Rejoined: text with \\& special chars\n",
      "Match: True\n",
      "\n",
      "Input:  math: $\\alpha + \\beta$\n",
      "Tokens: ['math', ':', ' ', '$', '\\\\alpha', ' ', '+', ' ', '\\\\beta', '$']\n",
      "Rejoined: math: $\\alpha + \\beta$\n",
      "Match: True\n",
      "\n",
      "Input:  % This is a comment line\n",
      "Next line.\n",
      "Tokens: ['% This is a comment line', '\\n', 'Next', ' ', 'line', '.']\n",
      "Rejoined: % This is a comment line\n",
      "Next line.\n",
      "Match: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: \"\\d\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\d\"? A raw string is also an option.\n",
      "<>:5: SyntaxWarning: \"\\d\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\d\"? A raw string is also an option.\n",
      "/var/folders/lv/jzpz148d0hs357twhd64v1r00000gp/T/ipykernel_68310/300664428.py:5: SyntaxWarning: \"\\d\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\d\"? A raw string is also an option.\n",
      "  - LaTeX commands with all arguments: \\textbf{...}, \\def\\cmd{...}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tokenize_latex(text):\n",
    "    \"\"\"Split LaTeX into meaningful tokens.\n",
    "    \n",
    "    Token types:\n",
    "    - LaTeX commands with all arguments: \\textbf{...}, \\def\\cmd{...}\n",
    "    - Single braces/brackets: { } [ ]\n",
    "    - Words (alphanumeric sequences)\n",
    "    - Whitespace (preserved)\n",
    "    - Punctuation and special characters\n",
    "    \"\"\"\n",
    "    import re\n",
    "    # Order matters! Try to match longer patterns first\n",
    "    pattern = r'''\n",
    "        \\\\[a-zA-Z]+\\*?                    # LaTeX command (e.g., \\textbf, \\section*)\n",
    "        |\\\\[^a-zA-Z]                       # Single-char commands (e.g., \\\\, \\&, \\{)\n",
    "        |[\\{\\}\\[\\]]                        # Braces and brackets (separate tokens)\n",
    "        |\\w+                               # Words (letters, digits, underscore)\n",
    "        |[ \\t]+                            # Horizontal whitespace (keep together)\n",
    "        |\\n                                # Newlines (separate token)\n",
    "        |%[^\\n]*                           # Comments (% to end of line)\n",
    "        |[^\\w\\s\\\\{}\\[\\]%]+                 # Punctuation/special chars\n",
    "        '''\n",
    "    return re.findall(pattern, text, re.VERBOSE)\n",
    "\n",
    "# Test the tokenizer\n",
    "test_cases = [\n",
    "    r\"in \\textbf{asset-intensive industries}, such\",\n",
    "    r\"\\def\\mytitle{Some Title}\" + \"\\n\",\n",
    "    r\"text with \\& special chars\",\n",
    "    r\"math: $\\alpha + \\beta$\",\n",
    "    r\"% This is a comment line\" + \"\\n\" + \"Next line.\",\n",
    "]\n",
    "\n",
    "print(\"Testing tokenizer:\")\n",
    "print(\"=\" * 80)\n",
    "for test in test_cases:\n",
    "    tokens = tokenize_latex(test)\n",
    "    print(f\"\\nInput:  {test}\")\n",
    "    print(f\"Tokens: {tokens}\")\n",
    "    print(f\"Rejoined: {''.join(tokens)}\")\n",
    "    print(f\"Match: {test == ''.join(tokens)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Comparing abstracts with improved tokenizer:\n",
      "================================================================================\n",
      "\\def\\mytitle{Navigating Digital \\old{Innovation}\\new{Transformation} in Asset-Intensive \\old{Industries}\\new{Companies}: A Process Model Informed by Design Science}\n",
      "\\def\\myabstract{Companies in \\new{\\textbf{}asset-intensive industries\\new{}}, such as aviation and railways, face unique digital transformation challenges due to the misalignment between the rapid evolution of digital technologies and decades-long asset lifecycles. Existing innovation frameworks are inadequate for managing this complexity, which in turn creates tensions between innovation requirements and operational reliability demands. This paper therefore investigates how asset-intensive companies can systematically integrate digital \\old{innovations}\\new{technologies}, while fully complying with regulatory constraints and safety requirements. We employ a design science approach in a study of Nederlandse Spoorwegen (NS), the Dutch national railway operator, focusing specifically on the implementation of AI-driven CCTV systems within the operations of NS. Drawing on a literature review and participant-observer as well as interview data, we develop six design propositions that address the key digital \\old{innovation}\\new{transformation} challenges of asset-intensive companies in the area of market readiness assessment, modular architecture, regulatory compliance, temporal coordination, ecosystem governance, and organizational capability development. Using these design propositions, we develop the Iterative Development \\& Adoption Model (IDAM) that operationalizes market maturity assessment through market readiness levels to guide make-or-buy transitions across four iterative phases: ideate, assess, realise, and review. This model includes a Development Reference Architecture for emerging technologies and an Integration Reference Architecture for more mature technologies, enabling concurrent sourcing strategies based on technological maturity. IDAM provides actionable guidance for decisions about technology adoption in asset-intensive contexts, thereby offering a systematic approach to innovation management in industries with very long asset lifecycles and huge regulatory constraints.}\n",
      "\\def\\mykeywords{design science; engineering design; technology adoption; digital transformation; product development; asset lifecycle; modular architecture; market readiness; operational reliability}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Comparing abstracts with improved tokenizer:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "old_tokens = tokenize_latex(old_abstract)\n",
    "new_tokens = tokenize_latex(new_abstract)\n",
    "matcher = difflib.SequenceMatcher(None, old_tokens, new_tokens)\n",
    "opcodes = matcher.get_opcodes()\n",
    "\n",
    "for tag, i1, i2, j1, j2 in opcodes:\n",
    "    old_text = ''.join(old_tokens[i1:i2])\n",
    "    new_text = ''.join(new_tokens[j1:j2])\n",
    "\n",
    "    if tag == 'equal':\n",
    "        print(old_text, end='')\n",
    "    elif tag == 'replace':\n",
    "        print(f\"\\\\old{{{old_text}}}\\\\new{{{new_text}}}\", end='')\n",
    "    elif tag == 'delete':\n",
    "        print(f\"\\\\old{{{old_text}}}\", end='')\n",
    "    elif tag == 'insert':\n",
    "        print(f\"\\\\new{{{new_text}}}\", end='')\n",
    "\n",
    "print()  # Final newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', ' ', 'is', ' ', '\\\\textbf', '{', 'bold', '}', ' ', 'text', ' ', 'with', ' ', '\\\\alpha', '.', '\\n', 'Companies', ' ', 'in', ' ', '\\\\textbf', '{', 'asset', '-', 'intensive', '}', ' ', 'industries']\n",
      "This is \\old{\\textbf}\\new{\\textit}{\\old{bold}\\new{italic}} text with \\old{\\alpha}\\new{\\beta}.\n",
      "Companies in \\old{\\textbf{}asset-intensive\\old{}} industries\n"
     ]
    }
   ],
   "source": [
    "text1 = r\"This is \\textbf{bold} text with \\alpha.\" + \"\\n\" + r\"Companies in \\textbf{asset-intensive} industries\"\n",
    "text2 = r\"This is \\textit{italic} text with \\beta.\" + \"\\n\" + r\"Companies in asset-intensive industries\"\n",
    "\n",
    "tokens1 = tokenize_latex(text1)\n",
    "tokens2 = tokenize_latex(text2)\n",
    "\n",
    "print(tokens1)\n",
    "matcher = difflib.SequenceMatcher(None, tokens1, tokens2)\n",
    "opcodes = matcher.get_opcodes()\n",
    "end_tokens = []\n",
    "for tag, i1, i2, j1, j2 in opcodes:\n",
    "    old_tokens = tokens1[i1:i2]\n",
    "    new_tokens = tokens2[j1:j2]\n",
    "\n",
    "    if tag == 'equal':\n",
    "        end_tokens += old_tokens\n",
    "    elif tag == 'replace':\n",
    "        end_tokens += ['\\\\old', '{'] + old_tokens + ['}', '\\\\new', '{'] + new_tokens + ['}'] \n",
    "    elif tag == 'delete':\n",
    "        end_tokens += ['\\\\old', '{'] + old_tokens + ['}']\n",
    "    elif tag == 'insert':\n",
    "        end_tokens += ['\\\\new', '{'] + new_tokens + ['}']\n",
    "\n",
    "print(\"\".join(end_tokens))  # Final newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using merged opcodes (min_equal_length=10):\n",
      "================================================================================\n",
      "\\def\\old{\\mytitl}\\new{\\mytitl}\n"
     ]
    }
   ],
   "source": [
    "def merge_opcodes(opcodes, old_text, new_text, min_equal_length=10):\n",
    "    \"\"\"\n",
    "    Merge opcodes to avoid fragmented changes.\n",
    "    If 'equal' segments between changes are very short, treat them as part of the change.\n",
    "    \"\"\"\n",
    "    if not opcodes:\n",
    "        return opcodes\n",
    "    \n",
    "    merged = []\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(opcodes):\n",
    "        tag, i1, i2, j1, j2 = opcodes[i]\n",
    "        \n",
    "        # Start accumulating if it's a change operation\n",
    "        if tag in ('replace', 'delete', 'insert'):\n",
    "            # Look ahead to see if we should merge with next operations\n",
    "            while i + 1 < len(opcodes):\n",
    "                next_tag, next_i1, next_i2, next_j1, next_j2 = opcodes[i + 1]\n",
    "                \n",
    "                # If next is 'equal' and short, check if there's another change after\n",
    "                if next_tag == 'equal' and (next_i2 - next_i1) < min_equal_length:\n",
    "                    # Look at the operation after the short equal segment\n",
    "                    if i + 2 < len(opcodes):\n",
    "                        after_tag, _, _, _, _ = opcodes[i + 2]\n",
    "                        if after_tag in ('replace', 'delete', 'insert'):\n",
    "                            # Merge: extend current operation through the equal segment\n",
    "                            i2 = next_i2\n",
    "                            j2 = next_j2\n",
    "                            i += 1  # Skip the short equal\n",
    "                            \n",
    "                            # Now merge the following change operation too\n",
    "                            i += 1\n",
    "                            tag2, i1_2, i2_2, j1_2, j2_2 = opcodes[i]\n",
    "                            i2 = i2_2\n",
    "                            j2 = j2_2\n",
    "                            tag = 'replace'  # Combined operation becomes 'replace'\n",
    "                            continue\n",
    "                \n",
    "                break\n",
    "            \n",
    "            merged.append((tag, i1, i2, j1, j2))\n",
    "        else:\n",
    "            # Keep 'equal' as-is\n",
    "            merged.append((tag, i1, i2, j1, j2))\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    return merged\n",
    "\n",
    "print(\"Using merged opcodes (min_equal_length=10):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "merged_opcodes = merge_opcodes(opcodes, old_abstract, new_abstract, min_equal_length=10)\n",
    "\n",
    "for tag, i1, i2, j1, j2 in merged_opcodes:\n",
    "    old_text = old_abstract[i1:i2]\n",
    "    new_text = new_abstract[j1:j2]\n",
    "    \n",
    "    if tag == 'equal':\n",
    "        print(old_text, end='')\n",
    "    elif tag == 'replace':\n",
    "        print(f\"\\\\old{{{old_text}}}\\\\new{{{new_text}}}\", end='')\n",
    "    elif tag == 'delete':\n",
    "        print(f\"\\\\old{{{old_text}}}\", end='')\n",
    "    elif tag == 'insert':\n",
    "        print(f\"\\\\new{{{new_text}}}\", end='')\n",
    "\n",
    "print()  # Final newline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative approach: Token-level comparison\n",
    "\n",
    "Instead of character-by-character comparison, we can tokenize the text (words + LaTeX commands) and compare at that level. This naturally groups LaTeX markup with the content it wraps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old abstract: 617 tokens\n",
      "New abstract: 620 tokens\n",
      "\n",
      "First 30 tokens of new abstract:\n",
      "['\\\\def', '\\\\mytitle', '{', 'Navigating', ' ', 'Digital', ' ', 'Transformation', ' ', 'in', ' ', 'Asset', '-', 'Intensive', ' ', 'Companies', ':', ' ', 'A', ' ', 'Process', ' ', 'Model', ' ', 'Informed', ' ', 'by', ' ', 'Design', ' ']\n",
      "\n",
      "Token-level similarity: 99.11%\n",
      "\n",
      "Token-level differences:\n",
      "\n",
      "REPLACE:\n",
      "  Old: 'Innovation'\n",
      "  New: 'Transformation'\n",
      "\n",
      "REPLACE:\n",
      "  Old: 'Industries'\n",
      "  New: 'Companies'\n",
      "\n",
      "INSERT:\n",
      "  Old: ''\n",
      "  New: '\\textbf{'\n",
      "\n",
      "INSERT:\n",
      "  Old: ''\n",
      "  New: '}'\n",
      "\n",
      "REPLACE:\n",
      "  Old: 'innovations'\n",
      "  New: 'technologies'\n",
      "\n",
      "REPLACE:\n",
      "  Old: 'innovation'\n",
      "  New: 'transformation'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: \"\\d\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\d\"? A raw string is also an option.\n",
      "<>:6: SyntaxWarning: \"\\d\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\d\"? A raw string is also an option.\n",
      "/var/folders/lv/jzpz148d0hs357twhd64v1r00000gp/T/ipykernel_57773/1492337232.py:6: SyntaxWarning: \"\\d\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\d\"? A raw string is also an option.\n",
      "  - LaTeX commands (\\textbf, \\def, etc.)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def tokenize_latex(text):\n",
    "    \"\"\"\n",
    "    Tokenize LaTeX text into meaningful chunks:\n",
    "    - LaTeX commands (\\textbf, \\def, etc.)\n",
    "    - Braces and special characters\n",
    "    - Words and whitespace\n",
    "    \"\"\"\n",
    "    # Pattern: LaTeX commands | special chars | words | whitespace\n",
    "    pattern = r'(\\\\[a-zA-Z]+|[{}]|\\w+|\\s+|[^\\w\\s\\\\{}]+)'\n",
    "    return re.findall(pattern, text)\n",
    "\n",
    "# Tokenize both abstracts\n",
    "old_tokens = tokenize_latex(old_abstract)\n",
    "new_tokens = tokenize_latex(new_abstract)\n",
    "\n",
    "print(f\"Old abstract: {len(old_tokens)} tokens\")\n",
    "print(f\"New abstract: {len(new_tokens)} tokens\")\n",
    "print(f\"\\nFirst 30 tokens of new abstract:\")\n",
    "print(new_tokens[:30])\n",
    "\n",
    "# Compare at token level\n",
    "token_matcher = difflib.SequenceMatcher(None, old_tokens, new_tokens)\n",
    "\n",
    "print(f\"\\nToken-level similarity: {token_matcher.ratio():.2%}\")\n",
    "print(\"\\nToken-level differences:\")\n",
    "\n",
    "for tag, i1, i2, j1, j2 in token_matcher.get_opcodes():\n",
    "    if tag != 'equal':\n",
    "        old_segment = ''.join(old_tokens[i1:i2])\n",
    "        new_segment = ''.join(new_tokens[j1:j2])\n",
    "        \n",
    "        print(f\"\\n{tag.upper()}:\")\n",
    "        print(f\"  Old: '{old_segment}'\")\n",
    "        print(f\"  New: '{new_segment}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-level comparison with LaTeX markup:\n",
      "================================================================================\n",
      "\\def\\mytitle{Navigating Digital \\old{Innovation}\\new{Transformation} in Asset-Intensive \\old{Industries}\\new{Companies}: A Process Model Informed by Design Science}\n",
      "\\def\\myabstract{Companies in \\new{\\textbf{}asset-intensive industries\\new{}}, such as aviation and railways, face unique digital transformation challenges due to the misalignment between the rapid evolution of digital technologies and decades-long asset lifecycles. Existing innovation frameworks are inadequate for managing this complexity, which in turn creates tensions between innovation requirements and operational reliability demands. This paper therefore investigates how asset-intensive companies can systematically integrate digital \\old{innovations}\\new{technologies}, while fully complying with regulatory constraints and safety requirements. We employ a design science approach in a study of Nederlandse Spoorwegen (NS), the Dutch national railway operator, focusing specifically on the implementation of AI-driven CCTV systems within the operations of NS. Drawing on a literature review and participant-observer as well as interview data, we develop six design propositions that address the key digital \\old{innovation}\\new{transformation} challenges of asset-intensive companies in the area of market readiness assessment, modular architecture, regulatory compliance, temporal coordination, ecosystem governance, and organizational capability development. Using these design propositions, we develop the Iterative Development & Adoption Model (IDAM) that operationalizes market maturity assessment through market readiness levels to guide make-or-buy transitions across four iterative phases: ideate, assess, realise, and review. This model includes a Development Reference Architecture for emerging technologies and an Integration Reference Architecture for more mature technologies, enabling concurrent sourcing strategies based on technological maturity. IDAM provides actionable guidance for decisions about technology adoption in asset-intensive contexts, thereby offering a systematic approach to innovation management in industries with very long asset lifecycles and huge regulatory constraints.}\n",
      "\\def\\mykeywords{design science; engineering design; technology adoption; digital transformation; product development; asset lifecycle; modular architecture; market readiness; operational reliability}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Token-level comparison with LaTeX markup:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for tag, i1, i2, j1, j2 in token_matcher.get_opcodes():\n",
    "    old_segment = ''.join(old_tokens[i1:i2])\n",
    "    new_segment = ''.join(new_tokens[j1:j2])\n",
    "    \n",
    "    if tag == 'equal':\n",
    "        print(old_segment, end='')\n",
    "    elif tag == 'replace':\n",
    "        print(f\"\\\\old{{{old_segment}}}\\\\new{{{new_segment}}}\", end='')\n",
    "    elif tag == 'delete':\n",
    "        print(f\"\\\\old{{{old_segment}}}\", end='')\n",
    "    elif tag == 'insert':\n",
    "        print(f\"\\\\new{{{new_segment}}}\", end='')\n",
    "\n",
    "print()  # Final newline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Practical example with shorter strings\n",
    "\n",
    "Let's look at a simpler example to understand the mechanics better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SIMPLE EXAMPLE\n",
      "============================================================\n",
      "Old: 'The quick brown fox jumps'\n",
      "New: 'The quick red fox leaps'\n",
      "\n",
      "Similarity: 75.00%\n",
      "\n",
      "Matching blocks:\n",
      "  'The quick ' at old[0:10] == new[0:10]\n",
      "  'r' at old[11:12] == new[10:11]\n",
      "  ' fox ' at old[15:20] == new[13:18]\n",
      "  'ps' at old[23:25] == new[21:23]\n",
      "\n",
      "Operations to transform old -> new:\n",
      "  KEEP:    'The quick '\n",
      "  DELETE:  'b'\n",
      "  KEEP:    'r'\n",
      "  REPLACE: 'own' -> 'ed'\n",
      "  KEEP:    ' fox '\n",
      "  REPLACE: 'jum' -> 'lea'\n",
      "  KEEP:    'ps'\n"
     ]
    }
   ],
   "source": [
    "# Simple example\n",
    "old_text = \"The quick brown fox jumps\"\n",
    "new_text = \"The quick red fox leaps\"\n",
    "\n",
    "simple_matcher = difflib.SequenceMatcher(None, old_text, new_text)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SIMPLE EXAMPLE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Old: '{old_text}'\")\n",
    "print(f\"New: '{new_text}'\")\n",
    "print(f\"\\nSimilarity: {simple_matcher.ratio():.2%}\\n\")\n",
    "\n",
    "print(\"Matching blocks:\")\n",
    "for i, j, n in simple_matcher.get_matching_blocks():\n",
    "    if n > 0:\n",
    "        print(f\"  '{old_text[i:i+n]}' at old[{i}:{i+n}] == new[{j}:{j+n}]\")\n",
    "\n",
    "print(\"\\nOperations to transform old -> new:\")\n",
    "for tag, i1, i2, j1, j2 in simple_matcher.get_opcodes():\n",
    "    if tag == 'equal':\n",
    "        print(f\"  KEEP:    '{old_text[i1:i2]}'\")\n",
    "    elif tag == 'replace':\n",
    "        print(f\"  REPLACE: '{old_text[i1:i2]}' -> '{new_text[j1:j2]}'\")\n",
    "    elif tag == 'delete':\n",
    "        print(f\"  DELETE:  '{old_text[i1:i2]}'\")\n",
    "    elif tag == 'insert':\n",
    "        print(f\"  INSERT:  '{new_text[j1:j2]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using SequenceMatcher for word-level comparison\n",
    "\n",
    "Instead of comparing character by character, we can compare word by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old abstract: 273 words\n",
      "New abstract: 273 words\n",
      "Word-level similarity: 97.80%\n",
      "\n",
      "Word-level differences:\n",
      "\n",
      "REPLACE:\n",
      "  Position: words 2-3 -> words 2-3\n",
      "  Old: 'Innovation'\n",
      "  New: 'Transformation'\n",
      "\n",
      "REPLACE:\n",
      "  Position: words 5-6 -> words 5-6\n",
      "  Old: 'Industries:'\n",
      "  New: 'Companies:'\n",
      "\n",
      "REPLACE:\n",
      "  Position: words 15-17 -> words 15-17\n",
      "  Old: 'asset-intensive industries,'\n",
      "  New: '\\textbf{asset-intensive industries},'\n",
      "\n",
      "REPLACE:\n",
      "  Position: words 74-75 -> words 74-75\n",
      "  Old: 'innovations,'\n",
      "  New: 'technologies,'\n",
      "\n",
      "REPLACE:\n",
      "  Position: words 138-139 -> words 138-139\n",
      "  Old: 'innovation'\n",
      "  New: 'transformation'\n"
     ]
    }
   ],
   "source": [
    "# Split abstracts into words\n",
    "old_words = old_abstract.split()\n",
    "new_words = new_abstract.split()\n",
    "\n",
    "word_matcher = difflib.SequenceMatcher(None, old_words, new_words)\n",
    "\n",
    "print(f\"Old abstract: {len(old_words)} words\")\n",
    "print(f\"New abstract: {len(new_words)} words\")\n",
    "print(f\"Word-level similarity: {word_matcher.ratio():.2%}\\n\")\n",
    "\n",
    "print(\"Word-level differences:\")\n",
    "for tag, i1, i2, j1, j2 in word_matcher.get_opcodes():\n",
    "    if tag != 'equal':\n",
    "        old_segment = ' '.join(old_words[i1:i2])\n",
    "        new_segment = ' '.join(new_words[j1:j2])\n",
    "        \n",
    "        print(f\"\\n{tag.upper()}:\")\n",
    "        print(f\"  Position: words {i1}-{i2} -> words {j1}-{j2}\")\n",
    "        if tag == 'replace':\n",
    "            print(f\"  Old: '{old_segment}'\")\n",
    "            print(f\"  New: '{new_segment}'\")\n",
    "        elif tag == 'delete':\n",
    "            print(f\"  Deleted: '{old_segment}'\")\n",
    "        elif tag == 'insert':\n",
    "            print(f\"  Inserted: '{new_segment}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key takeaways about SequenceMatcher\n",
    "\n",
    "1. **Initialization**: `SequenceMatcher(isjunk, a, b)` creates a matcher for two sequences\n",
    "\n",
    "2. **Similarity ratio**: `ratio()` returns a float [0, 1] indicating how similar the sequences are\n",
    "\n",
    "3. **Matching blocks**: `get_matching_blocks()` returns `(i, j, n)` tuples showing where sequences match\n",
    "   - `a[i:i+n] == b[j:j+n]`\n",
    "\n",
    "4. **Operations**: `get_opcodes()` returns `(tag, i1, i2, j1, j2)` tuples describing transformations\n",
    "   - 'equal': sequences match\n",
    "   - 'replace': substitute a[i1:i2] with b[j1:j2]\n",
    "   - 'delete': remove a[i1:i2]\n",
    "   - 'insert': add b[j1:j2]\n",
    "\n",
    "5. **Flexibility**: Works with any sequences (strings, lists, etc.) and at any granularity (chars, words, lines)\n",
    "\n",
    "6. **Use cases**: \n",
    "   - Text diff tools\n",
    "   - Finding changes between documents\n",
    "   - Plagiarism detection\n",
    "   - Version control systems"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latex-tools (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
